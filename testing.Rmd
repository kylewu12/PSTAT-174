---
title: "tester"
author: "Kyle Wu"
date: "2023-02-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(AER)
library(dynlm)
library(forecast)
library(readxl)
library(stargazer)
library(scales)
library(quantmod)
library(urca)
```


### Detrended Total Vehicle Sales

```{r}
total_log <- ts(log(total_vehicles$TOTALNSA), start = c(1976,01), frequency = 12)

```

```{r}
total_log <- ts(log(total_vehicles$TOTALNSA), start = c(1976,01), frequency = 12)

diff_total_log <- diff(total_log)

decomp <- seas(total_log, x11 = "")

detrended <- total_log - decomp$data[, "trend"]

plot(total_log)
plot(detrended)
plot(diff_total_log)
adf.test(total_log)

kpss.test(diff_total_log, null = "Trend")

kpss.test(detrended, null = "Trend")
adf.test(diff_total_log)
attempt <- dynlm(detrended ~ L(detrended, 1) + L(detrended, 12))

model0 <- dynlm(diff_total_log ~ 1)
model11 <- dynlm(diff_total_log ~ season(diff_total_log), data = total_log)
anova(model0, model11)

plot(diff_total_log) +

lines(fitted(model0), col = 2) +

lines(fitted(model11), col = 4)
```

```{r}
lambda <- total_vehicles %>%
  features(TOTALNSA, features = guerrero) %>%
  pull(lambda_guerrero)

total_adjusted <- total_vehicles %>%
  autoplot(box_cox(TOTALNSA, lambda)) 

total_vehicles <- total_vehicles %>%
  dplyr::mutate(total_adjusted = box_cox(TOTALNSA, lambda))

lambda2 <- auto_production %>%
  features(DAUPNSA, features = guerrero) %>%
  pull(lambda_guerrero)

production_adjusted <- auto_production %>%
  autoplot(box_cox(DAUPNSA, lambda2)) 

auto_production <- auto_production %>%
  dplyr::mutate(production_adjusted = box_cox(DAUPNSA, lambda2))

lambda3 <- fuel_prices %>%
  features(CUSR0000SETB01, features = guerrero) %>%
  pull(lambda_guerrero)

fuel_adjusted <- fuel_prices %>%
  autoplot(fabletools::box_cox(CUSR0000SETB01, lambda3))

fuel_prices <- fuel_prices %>%
  dplyr::mutate(fuel_adjusted = fabletools::box_cox(CUSR0000SETB01, lambda3))
```


### Total Vehicles and Bank Prime Rate Loan:
```{r}
total

model2 <- dynardl()
```

```{r}
rate <- ts(bank_rate$MPRIME, start = c(1949, 1), frequency = 12)
kpss.test(rate, null = "Trend")

rate <- diff(rate)
kpss.test(rate, null = "Trend")
adf.test(rate)

total_rate_analysis <- ts.intersect(diff_total_log, rate)

plot(rate)

autoplot(total_rate_analysis)

model1 <- dynlm(diff_total_log ~ L(diff_total_log, 1:14) + L(rate, 0:15) + season(diff_total_log), data = total_rate_analysis)

summary(model1)

auto_ardl(diff_total_log ~ rate, data = total_rate_analysis, max_order = 20)

checkresiduals(model1)
```

```{r}
try_dat <- combined %>% filter(DATE > "1976-01-01") %>%
  mutate(diff_total_log = difference(difference(log(TOTALNSA, 12))),
         diff_rate = difference(MPRIME))

try_fit <- auto.arima(try_dat$diff_total_log, xreg = try_dat$diff_rate, stationary = TRUE)

checkresiduals(try_fit)
```

```{r}
stuff <- combined %>% filter(DATE >= "1976-01-01") %>%
  model(
    lag0 = ARIMA(TOTALNSA ~ pdq(d = 0) + MPRIME),
    lag1 = ARIMA(TOTALNSA ~ pdq(d = 0) + MPRIME + lag(MPRIME)),
    lag2 = ARIMA(TOTALNSA ~ pdq(d = 0) + MPRIME + lag(MPROME) + lag(MPRIME, 2))
  )

glance(stuff)
```


### Total Vehicles and New Car CPI:
```{r}
car_cpi <- ts(log(cpi_newcar$CUSR0000SETA01), start = c(1953, 1), frequency = 12)
kpss.test(car_cpi, null = "Trend")

car_cpi <- diff(car_cpi)
kpss.test(car_cpi, null = "Trend")
adf.test(car_cpi)

total_rate_analysis <- ts.intersect(diff_total_log, car_cpi)

plot(rate)

autoplot(total_rate_analysis)

model1 <- dynlm(diff_total_log ~ L(diff_total_log, 1:3) + L(rate, 0:5), data = total_rate_analysis)

summary(model1)
```

### Total Vehicles and Gas CPI:
```{r}
gas_cpi <- ts(log(fuel_prices$CUSR0000SETB01), start = c(1968, 2), frequency = 12) 
kpss.test(gas_cpi, null = "Trend")

gas_cpi <- diff(gas_cpi, 1)
kpss.test(gas_cpi, null = "Trend")
adf.test(gas_cpi)

total_gas_analysis <- ts.intersect(diff_total_log, gas_cpi)

autoplot(total_gas_analysis)

model6 <- dynlm(diff_total_log ~ L(diff_total_log, c(1:12)) + L(gas_cpi, 0:12) + season(diff_total_log), data = total_gas_analysis)

summary(model6)

checkresiduals(model6)

auto_ardl(diff_total_log ~ gas_cpi, data = total_gas_analysis, max_order = 24)
```

```{r}
gas_car_dat <- combined %>% filter(DATE >= "1976-01-01") %>%
  mutate(diff_total_log = difference(log(TOTALNSA),12) %>% difference(),
         diff_gas_cpi = difference(CUSR0000SETB01))

fit <- gas_car_dat %>%
  model(
    lag0 = ARIMA(diff_total_log ~ pdq(d = 0) + diff_gas_cpi),
    lag1 = ARIMA(diff_total_log ~ pdq(d = 0) + diff_gas_cpi + lag(diff_gas_cpi)),
    lag2 = ARIMA(diff_total_log ~ pdq(d = 0) + diff_gas_cpi + lag(diff_gas_cpi) + lag(diff_gas_cpi, 2)),
    lag3 = ARIMA(diff_total_log ~ pdq(d = 0) + diff_gas_cpi + lag(diff_gas_cpi) + lag(diff_gas_cpi, 2) + lag(diff_gas_cpi, 3)))

glance(fit)

fit_best <- gas_car_dat %>%
  model(ARIMA(diff_total_log ~ pdq(d = 0) + diff_gas_cpi + lag(diff_gas_cpi) + lag(diff_gas_cpi, 2) + lag(diff_gas_cpi, 3)))

fit_best %>% gg_tsresiduals()
report(fit_best)
augment(fuel_fit) %>% filter(.model == 'search') %>%
  features(.innov, ljung_box, lag = 10, dof = 3)

augment(fit_best) %>% features(.innov, ljung_box, lag = 10, dof = 3)
```
### Total Vehicle and Unemployment Rate:
```{r}
unemp <- ts(unemployment$UNRATE, start = c(1948, 1), frequency = 12)

unemp <- diff(unemp)

kpss.test(unemp, null = "Trend")
adf.test(unemp)

autoplot(unemp)

total_unemp_analysis <- ts.intersect(diff_total_log, unemp)

autoplot(total_unemp_analysis)

model8 <- dynlm(diff_total_log ~ L(diff_total_log, 1:12) + L(unemp, 0:1) + season(diff_total_log), data = total_unemp_analysis)

summary(model8)

checkresiduals(model8)
```
```{r}
(fit <- auto.arima(uschange[,"Consumption"],
  xreg=uschange[,"Income"]))

veh_unemp_fit <- auto.arima(model8, xreg = model.matrix(model8))
```


### Total Vehicles and Domestic Auto Production:
```{r}

auto_prod <- ts(log(auto_production$DAUPNSA), start = c(1993, 1), frequency = 12)

kpss.test(auto_prod, null = "Trend")

auto_prod <- diff(auto_prod, 1)
kpss.test(auto_prod, null = "Trend")
adf.test(auto_prod)

total_prod_analysis <- ts.intersect(diff_total_log, auto_prod) 

model51 <- dynlm(diff_total_log ~ L(diff_total_log, 1:10) + L(auto_prod, 0:10) + season(total_log), data = total_prod_analysis)

summary(model51)

Anova(model5, model51)

plot(model51)
autoplot(total_prod_analysis)

checkresiduals(model51)


auto_ardl(diff_total_log ~ auto_prod, data = total_prod_analysis, max_order = 24)

order <- 1:24
sapply
BICs <- base::sapply(order, function(x)
  BIC(dynlm(diff_total_log ~ L(diff_total_log, 1:x) + L(auto_prod, 1:x))))

```

```{r}

xreg <- model.matrix(model51, newdata = total_prod_analysis)

model_arima <- auto.arima(total_prod_analysis[, "diff_total_log"], xreg = xreg)

plot(total_prod_analysis[, "diff_total_log"])
```


```{r}
mod_data <- combined %>% filter(DATE >= "1976-01-01")
mod <- lm(TOTALNSA ~ MPRIME, data = mod_data)
```

```{r}
auto_production %>%
  mutate(diff_prod = difference(production_adjusted, 12) %>% difference()) %>%
  features(diff_prod, unitroot_kpss) %>%
  gt::gt()

diff1 <- autoplot(ts(difference(auto_production$production_adjusted), start = c(1993,01), frequency = 12))
diff_season <- autoplot(ts(difference(auto_production$production_adjusted, 12) %>% difference(), start = c(1993,01), frequency = 12))

grid.arrange(diff1, diff_season)
```




After we have successfully differenced our data, we can then begin to
consider what types of models to fit to our stationary time series. When
considering ARIMA models, there are two model types that we can use:
autoregressive models and moving average models.





We will first discuss autoregressive models. In autoregression, our goal
is to forecast the variable of interest using linear combinations of
previous values of the variable. This means that in an autoregression,
the variable is regressed on itself. An model that utilizes
autoregression of order p can be denoted by
$$y_t = c + \phi_1y_{t-1} + \phi_2y_{t-2} + \cdots + \phi_py_{t-p} + \epsilon_t$$,
where $\epsilon_t$ denotes white noise. In such a case, we would say
that our model is an AR(p) model. For these types of models, we face
certain constraints, mainly:

-   For an AR(1) model: $-1 < \phi_1 < 1$

-   For an AR(2) model:
    $-1 < \phi_2 < 1, \phi_1 + \phi_2 < 1, \phi_2-\phi_1 < 1$.

While autoregression models use past values of itself, moving average
models use past forecast errors in a regression_like model
[@forecastbook]. Moving average models take on the form
$$y_t = c + \epsilon_t + \theta_1\epsilon_{t-1} + \theta_2\epsilon_{t-2} + \cdots + \theta_q\epsilon_{t-q}$$,
where $\epsilon_t$ is white noise. In such a case, we would say that our
model is an MA(q) model. Each value of $y_t$ can be thought of as a
weighted moving average of past forecast errors. MA models also have
stationarity constraints which are as follows:

-   For an MA(1) model: $-1 < \theta_1 < 1$

-   For an MA(2) model:
    $-1 < \theta_2 < 1, \theta_1 + \theta_2 >1, \theta_1-\theta_2 < 1$.
    
    
### Non-Seasonal ARIMA Models

For our non-seasonal time series we can appropriately use Non-seasonal
ARIMA models which follow the form
$$y_t' = c + \phi_1y_{t-1}' + \cdots + \phi_py_{t-p}' + \theta_1\epsilon_{t-1} + \cdots + \theta_1\epsilon_{t-q} + \epsilon_t$$

To find the best model, we will have to create ACF and PACF plots so
that we may visually decide which ARIMA model may best model our
stationary time series, we will also take advantage of functions which
will pick the best ARIMA model and then compare the given answers. The
ACF will allow us to decide which MA nmodel to use and the PACF will
allow us to decide which AR model to use.

In the case of fuel prices:

```{r}
fuel_prices %>%
  gg_tsdisplay(difference(fuel_adjusted), plot_type = 'partial')

fit <- fuel_prices %>%
  model(ARIMA(fuel_adjusted))

report(fit)
```

```{r}
fuel_fit <- fuel_prices %>%
  model(arima310 = fable::ARIMA(fuel_adjusted ~ pdq(2,1,0)),
        arima011 = fable::ARIMA(fuel_adjusted ~ pdq(0,1,1)),
        stepwise = fable::ARIMA(fuel_adjusted),
        search = fable::ARIMA(fuel_adjusted, stepwise = FALSE))
fuel_fit

glance(fuel_fit) %>% arrange(AICc) %>% select(.model:BIC)

fuel_fit %>% select(search) %>% gg_tsresiduals()

augment(fuel_fit) %>% filter(.model == 'search') %>%
  features(.innov, ljung_box, lag = 10, dof = 3)
```

### Seasonal ARIMA Models

Combining autoregression and moving average models along with
differencing allows us to obtain ARIMA models, which stands for Auto
Regressive Integrated Moving Averge. ARIMA models can be written as

```{r}
auto_production_ts


auto_production %>%
  gg_tsdisplay(difference(production_adjusted, 12) %>% difference(), plot_type = 'partial', lag = 36)       

auto_production <- auto_production %>% mutate(production_log_adjust =  difference(log(DAUPNSA), 12) %>% difference())

fit3 <- auto_production %>% filt
  model(ARIMA())

fit3 <- auto.arima(diff(log(auto_production$DAUPNSA), 12) %>% diff())

fit_things <- auto_production %>% model(ARIMA(production_log_adjust))

report(fit_things)

gg_tsresiduals(fit_things)

augment(fit_things) %>% features(.innov, ljung_box, lag = 10, dof = 3)
forecast(fit3, h=10)

fit_things %>% forecast(h = 24) %>% autoplot(auto_production)

autoplot(auto_production)
plot(forecast(fit3, h=30))

trend <- auto

thingy <- auto.arima(auto_production$DAUPNSA)

auto_production2 <- auto_production %>% filter(DATE <= "2020-01-01")

thingy2 <-auto.arima(auto_production2$DAUPNSA)

auto_production2 <- auto_production2 %>%
  mutate(pre_difference = difference(auto_prodction2$DAUPNSA))
  
plot(auto_prodction2$pre_difference)

thingy.forecast <- forecast(thingy, level = c(95), h = 50)
thingy2.forecast <- forecast(thingy2, level = c(95), h = 36)

autoplot(thingy.forecast)
autoplot(thingy2.forecast)

grid.arrange(autoplot(auto_production), autoplot(thingy2.forecast))

a <- forecast(fit3, level = c(95), h = 50)
autoplot(a + seasonaldummy(auto_production))
```

```{r, include=FALSE}
fit <- auto.arima(diff(fuel_prices$CUSR0000SETB01))
fit
forecasting <- forecast(fit, h = 30) 

plot(forecasting)

```

```{r}
total_vehicles %>%
  ACF(difference(total_adjusted, 12) %>% difference()) %>%
  autoplot() + labs(title = "Total Vehicles Sold")

total_vehicles %>%
  mutate(diff_total = difference(total_adjusted)) %>%
  features(diff_total, unitroot_kpss)

total_vehicles %>%
  features(total_adjusted, unitroot_ndiffs)

total_vehicles %>% model(ARIMA(total_adjusted)) %>% report()
```

After we have appropriately differenced our models so that they are
stationary, we can then begin to consider what type of models to fit to
our data.


```{r, include=FALSE}
total_vehicles$TOTALNSA <- ts(total_vehicles$TOTALNSA, start = c(1976,01), frequency = 12)

plot(total_vehicles$TOTALNSA)

dopen <- diff(total_vehicles$TOTALNSA, 1)

ddopen <- diff(dopen, 1)

plot(dopen)
plot(ddopen)
ar1_model<- auto.arima(ddopen)

ar1_model

forecasts_AR1<- forecast(ar1_model, h = 30)

plot(forecasts_AR1)
```

```{r, include=FALSE}
cpi_newcar$CUSR0000SETA01 <- ts(cpi_newcar$CUSR0000SETA01, start = c(1953,01), frequency = 12)

plot(cpi_newcar$CUSR0000SETA01)

dopen2 <- diff(cpi_newcar$CUSR0000SETA01, 1)

ddopen2 <- diff(dopen2, 1)

plot(dopen2)
plot(ddopen2)
ar2_model<- auto.arima(dopen2)

ar2_model

forecasts_AR2<- forecast(ar2_model, h = 30)

plot(forecasts_AR2)
```

```{r, include=FALSE}
plot(auto_production$DAUPNSA)

tre <- time(auto_production$DAUPNSA) - mean(time(auto_production$DAUPNSA))

tre2 <- tre^2

regmodel2 = lm(auto_production$DAUPNSA ~ tre)

summary(regmodel2)

acf2(resid(regmodel2))

adjreg2 = sarima(auto_production$DAUPNSA, 3, 1, 3, xreg = cbind(tre))

adjreg2$fit$coef


```

```{r, include=TRUE}
decomp_tv <- total_vehicles %>%
  model(stl = STL(TOTALNSA))

components(decomp_tv) %>% autoplot()
```

```{r, include=FALSE}
trial <- autoplot(combined %>% filter(DATE > "1975-12-01"), TOTALNSA)
```

```{r, message=FALSE, warning=FALSE}
GGally::ggpairs(combined[,2:6])
```

```{r, include=FALSE}
require(urca)
total_vehicles$TOTALNSA %>% ur.kpss %>% summary() 
auto_production$DAUPNSA %>% ur.kpss %>% summary()
bank_rate$MPRIME %>% ur.kpss %>% summary()
fuel_prices$CUSR0000SETB01 %>% ur.kpss %>% summary()
```



```{r, include=FALSE}
plot(ts(auto_production$production_adjusted))

trend = time(auto_production$production_adjusted) - mean(time(auto_production$production_adjusted))

regmodel = lm(auto_production$production_adjusted ~ trend)

summary(regmodel)

acf2(resid(regmodel))

adjreg = sarima(auto_production$production_adjusted, 0,1,3, xreg = cbind(trend))

```

```{r, include=FALSE}
total_vehicles %>% features(log(TOTALNSA), unitroot_kpss)
auto_production %>% features(log(DAUPNSA), unitroot_kpss)
bank_rate %>% features(MPRIME, unitroot_kpss)
fuel_prices %>% features(log(CUSR0000SETB01), unitroot_kpss)
unemployment %>% features(UNRATE, unitroot_kpss)
unemployment %>% features(UNRATE, unitroot_kpss)
```

```{r}
# Total Auto Production and Bank Prime Rate Loans from 1976-01-01
tap_bpm_data <- combined %>% filter(DATE >= "1976-01-01")
tap_bpm <- dynlm::dynlm(TOTALNSA ~ MPRIME + L(TOTALNSA), data = tap_bpm_data)
summary(tap_bpm)

plot.ts(tap_bpm_data$TOTALNSA)
lines(fitted(tap_bpm), col = "red")

trys <- dynlm(total_vehicles$TOTALNSA ~ Lag(total_vehicles$TOTALNSA, 1) + Lag(total_vehicles$TOTALNSA, 12))

plot.ts(total_vehicles$TOTALNSA)
lines(fitted(trys), col = "red")
```

```{r}
tap_bpm <- combined %>%
  filter(DATE >= "1976-01-01") %>% 
  model(ARIMA(TOTALNSA ~ MPRIME + lag(MPRIME) + lag(MPRIME, 2) + lag(MPRIME, 3)))

report(tap_bpm)

tap_bpm %>% gg_tsresiduals()
```

```{r}
augment(tap_bpm) %>%
  features(.innov, ljung_box, dof = 3, lag = 24)
```


### Trying to see what code does

```{r}
USMacroSWQ <- read_xlsx("Data/us_macro_quarterly.xlsx",
                         sheet = 1,
                         col_types = c("text", rep("numeric", 9)))

# format date column
USMacroSWQ$X__1 <- as.yearqtr(USMacroSWQ$X__1, format = "%Y:0%q")

# adjust column names
colnames(USMacroSWQ) <- c("Date", "GDPC96", "JAPAN_IP", "PCECTPI", 
                          "GS10", "GS1", "TB3MS", "UNRATE", "EXUSUK", "CPIAUCSL")
```

```{r}
data("USDistLag", package = "lmtest")
dfm1 <- dynlm(consumption ~ gnp + L(consumption), data = USDistLag)
dfm2 <- dynlm(consumption ~ gnp + L(gnp), data = USDistLag)
plot(USDistLag[, "consumption"]) +
lines(fitted(dfm1), col = 2) +
lines(fitted(dfm2), col = 4)
if(require("lmtest")) encomptest(dfm1, dfm2)
```


```{r, include = FALSE}
total_log <- ts(log(total_vehicles$TOTALNSA), start = c(1976,01), frequency = 12) 
diff_total_log <- diff(total_log)

auto_prod <- ts(log(auto_production$DAUPNSA), start = c(1993, 1), frequency = 12)
auto_prod <- diff(auto_prod)

total_prod_analysis <- ts.intersect(diff_total_log, auto_prod)

auto_ardl(diff_total_log ~ auto_prod, data = total_prod_analysis, max_order = 24, selection = "BIC")
auto_ardl(diff_total_log ~ auto_prod, data = total_prod_analysis, max_order = 24)
auto_ardl(diff_total_log ~ auto_prod, data = total_prod_analysis, max_order = 24)
VARselect(diff_total_log, lag.max = 24)
VARselect(auto_prod, lag.max = 24)
```

```{r}
prod_total_modelvarbic <- dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12) + L(auto_prod, 0:6) + season(diff_total_log), data = total_prod_analysis)

prod_total_model_auto <- dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12) + L(auto_prod, 0:10) + season(diff_total_log), data = total_prod_analysis)


# checkresiduals(prod_total_modelvarbic) 
forecast::checkresiduals(prod_total_model_auto)

# par(mfrow = c(2,2))
# plot(prod_total_modelvarbic)


par(mfrow = c(2,2))
plot(prod_total_model_auto)
```
From the outputs, above showing our residual analysis, we can see that the residual values we obtain are consistent with being white noise and that all our values appear normally distributed. Additionally, the p-value we got from the Breusch-Godfrey test was 0.0879 > 0.05, therefore we can conclude that it is likely that our residuals are not serially correlated. We can then conclude that our current model is appropriate with modeling the true data. We can now test to see if adding the lags for domestic auto production were helpful in predicting the number of vehicles sold.



```{r}
prod_total_model_auto <- dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12) + L(auto_prod, 0:10) + season(diff_total_log), data = total_prod_analysis)
prod_total_noprod <- dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12) + season(diff_total_log), data = total_prod_analysis)

anova(prod_total_model_auto, prod_total_noprod) 
```
From the Granger-Causality test conducted above, we get a p-value < 0.05, therefore we can reject the null hypothesis and conclude that it is likely that domestic auto production Granger-causes the number of vehicles sold. For the following time series, the same process will be followed with the output being listed in a table.

```{r}
plot(stats::diffinv(total_prod_analysis[,"diff_total_log"], lag = 1, difference = 1, xi = 6.819252)) +
  lines(stats::diffinv(-fitted(prod_total_model_auto), lag = 1, difference = 1, xi = 6.952251), col = 2) + title("Actual (Black) vs Fitted (Red) Model")

  
```


### Total Vehicles Sold and Unemployment Rate:



```{r}
unemp <- ts(unemployment$UNRATE, start = c(1948, 1), frequency = 12)
unemp <- diff(unemp)
total_unemp_analysis <- ts.intersect(diff_total_log, unemp)
```

```{r, include = FALSE}
ARDL::auto_ardl(diff_total_log ~ unemp, data = total_unemp_analysis, max_order = 24, selection = "BIC")
ARDL::auto_ardl(diff_total_log ~ unemp, data = total_unemp_analysis, max_order = 24)
vars::VARselect(unemp, lag.max = 24)
vars::VARselect(diff_total_log, lag.max = 24)

unemp_total_modelvarbic <-  dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12) + L(unemp, 0:1) + season(diff_total_log), data = total_unemp_analysis)
unemp_total_model_autobic <- dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12) + L(unemp, 0:12) + season(diff_total_log), data = total_unemp_analysis)
unemp_total_model_autoaic <- dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:15) + L(unemp, 0:14) + season(diff_total_log), data = total_unemp_analysis)

checkresiduals(unemp_total_model_autobic)
checkresiduals(unemp_total_model_autoaic)
checkresiduals(unemp_total_modelvarbic)
```


```{r, include = FALSE}
unemp_total_modelvar_bic <-  dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12) + L(unemp, 0:1) + season(diff_total_log), data = total_unemp_analysis)

checkresiduals(unemp_total_modelvar_bic)
```

```{r}
unemp_total_nounemp <- dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12), data = total_unemp_analysis)

anova(unemp_total_modelvar_bic, unemp_total_nounemp) 
```


```{r}
model_emp <- c("ARDL(12,1)", "ARDL(12, 14)", "ARDL(15,14)")
selection_crit_emp <- c("Individually Selected BIC", "Auto_ARDL BIC", "Auto_ARDL AIC")
significant_p_emp <- c(0.2617, 0.04512, 0.00733)
emp_adequacy <- c("Adequate", "Inadequate", "Inadequate")
emp_granger_causality_F <- c(16.105, NULL, NULL)
emp_granger_p <- c("< 0.01", "", "")

emp.tib <- tibble(model_emp, selection_crit_emp, significant_p_emp, emp_adequacy, emp_granger_p)

emp.tib %>%
  gt::gt() %>%
  gt::tab_header(title = "Total Vehicle Sales and Unemployment Model Analysis (Breusch-Godfrey Test)") %>%
  gt::cols_label(model_emp = "Model",
             selection_crit_emp = "Selection Criteria",
             significant_p_emp = "P-Values",
             emp_adequacy = "Model Adequacy",
             emp_granger_p = "Granger Causality P-Value")
```



```{r}
unemp_total_modelvar_bic <-  dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12) + L(unemp, 0:1) + season(diff_total_log), data = total_unemp_analysis)
unemp_total_nounemp <- dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12) + season(total_log), data = total_unemp_analysis)

anova(unemp_total_modelvar_bic, unemp_total_nounemp) 
```

```{r}
plot(diffinv(total_unemp_analysis[,"diff_total_log"], lag = 1, difference = 1, xi = 6.785814)) +
  lines(diffinv(-fitted(unemp_total_modelvar_bic), lag = 1, difference = 1, xi = 6.877193), col = 2) + title("Actual vs Fitted for Unemployment and Total Vehicles Sold")
```


### Total Vehicles Sold and Gas CPI:


```{r}
gas_cpi <- ts(log(fuel_prices$CUSR0000SETB01), start = c(1968, 2), frequency = 12) 

gas_cpi <- diff(gas_cpi)

total_gas_analysis <- ts.intersect(diff_total_log, gas_cpi)
```

```{r, include = FALSE}
ARDL::auto_ardl(diff_total_log ~ gas_cpi, data = total_gas_analysis, max_order = 24, selection = "BIC")
ARDL::auto_ardl(diff_total_log ~ gas_cpi, data = total_gas_analysis, max_order = 24)
vars::VARselect(gas_cpi, lag.max = 24)
vars::VARselect(diff_total_log, lag.max = 24)

gas_total_modelvarbic <-  dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12) + L(gas_cpi, 0:2) + season(diff_total_log), data = total_gas_analysis)
gas_total_model_autobic <- dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12) + L(gas_cpi, 0:12) + season(diff_total_log), data = total_gas_analysis)
gas_total_model_autoaic <- dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:15) + L(gas_cpi, 0:12) + season(diff_total_log), data = total_gas_analysis)

checkresiduals(gas_total_modelvarbic)
checkresiduals(gas_total_model_autobic)
checkresiduals(gas_total_model_autoaic)
```

```{r}
gas_total_nogas <- dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12), data = total_gas_analysis)

anova(gas_total_model_autobic, gas_total_nogas) 
```


```{r}
model_gas <- c("ARDL(12,2)", "ARDL(12, 12)", "ARDL(15,12)")
selection_crit_gas <- c("Individually Selected BIC", "Auto_ARDL BIC", "Auto_ARDL AIC")
significant_p_gas <- c(0.0331, 0.1262, 0.03477)
gas_adequacy <- c("Inadequate", "Adequate", "Inadequate")
gas_granger_p <- c("", "< 0.01", "")

gas.tib <- tibble(model_gas, selection_crit_gas, significant_p_gas, gas_adequacy, gas_granger_p)

gas.tib %>%
  gt::gt() %>%
  gt::tab_header(title = "Total Vehicle Sales and Unemployment Model Analysis (Breusch-Godfrey Test)") %>%
  gt::cols_label(model_gas = "Model",
             selection_crit_gas = "Selection Criteria",
             significant_p_gas = "P-Values",
             gas_adequacy = "Model Adequacy",
             gas_granger_p = "Granger Causality P-Value")
```

```{r}
plot(diffinv(total_gas_analysis[,"diff_total_log"], lag = 1, difference = 1, xi = 6.785814)) +
  lines(diffinv(-fitted(gas_total_model_autobic), lag = 1, difference = 1, xi = 6.877193), col = 2) + title("Actual vs Fitted for Unemployment and Total Vehicles Sold")
```

### Total Vehicles Sold and Bank Prime Rate Loan:

```{r}
rate <- ts(bank_rate$MPRIME, start = c(1949, 1), frequency = 12)

rate <- diff(rate)

total_rate_analysis <- ts.intersect(diff_total_log, rate)
```

```{r, include = FALSE}
ARDL::auto_ardl(diff_total_log ~ rate, data = total_rate_analysis, max_order = 24, selection = "BIC")
ARDL::auto_ardl(diff_total_log ~ rate, data = total_rate_analysis, max_order = 24)
vars::VARselect(rate, lag.max = 24)
vars::VARselect(diff_total_log, lag.max = 24)

rate_total_modelvarbic <-  dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12) + L(rate, 0:13) + season(total_log), data = total_rate_analysis)
rate_total_model_autobic <- dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12) + rate + season(total_log), data = total_rate_analysis)
rate_total_model_autoaic <- dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:14) + L(rate, 0:13) + season(total_log), data = total_rate_analysis)

checkresiduals(rate_total_model_autobic)
checkresiduals(rate_total_model_autoaic)
checkresiduals(rate_total_modelvarbic)
```
```{r}
rate_total_norate <- dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12), data = total_rate_analysis)

anova(rate_total_model_autobic, rate_total_norate) 
```

```{r}
model_rate <- c("ARDL(12,13)", "ARDL(12, 0)", "ARDL(14,13)")
selection_crit_rate <- c("Individually Selected BIC", "Auto_ARDL BIC", "Auto_ARDL AIC")
significant_p_rate <- c(0.01152, 0.05509, 0.0008)
rate_adequacy <- c("Indequate", "Adequate", "Inadequate")
rate_granger_p <- c("", "< 0.01", "")

rate.tib <- tibble(model_rate, selection_crit_rate, significant_p_rate, rate_adequacy, rate_granger_p)

rate.tib %>%
  gt::gt() %>%
  gt::tab_header(title = "Total Vehicle Sales and Bank Prime Rates Model Analysis (Breusch-Godfrey Test)") %>%
  gt::cols_label(model_rate = "Model",
             selection_crit_rate = "Selection Criteria",
             significant_p_rate = "P-Values",
             rate_adequacy = "Model Adequacy",
             rate_granger_p = "Granger Causality P-Value")
```

```{r}
plot(diffinv(total_rate_analysis[,"diff_total_log"], lag = 1, difference = 1, xi = 6.785814)) +
  lines(diffinv(-fitted(rate_total_model_autobic), lag = 1, difference = 1, xi = 6.877193), col = 2) + title("Actual vs Fitted for Unemployment and Total Vehicles Sold")
```

### Trying Forecasts:

```{r}
library(AER)
library(dynlm)
library(forecast)
library(readxl)
library(stargazer)
library(scales)
library(quantmod)
library(urca)
library(quantmod)
```

```{r}
USMacroSWQ <- read_xlsx("us_macro_quarterly.xlsx",
                         sheet = 1,
                         col_types = c("text", rep("numeric", 9)))

USMacroSWQ$...1 <- as.yearqtr(USMacroSWQ$...1, format = "%Y:0%q")

# adjust column names
colnames(USMacroSWQ) <- c("Date", "GDPC96", "JAPAN_IP", "PCECTPI", 
                          "GS10", "GS1", "TB3MS", "UNRATE", "EXUSUK", "CPIAUCSL")

GDP <- xts(USMacroSWQ$GDPC96, USMacroSWQ$Date)["1960::2013"]

# GDP growth series as xts object
GDPGrowth <- xts(400 * log(GDP/Lag(GDP)))

GDPGrowth_ts <- ts(GDPGrowth, 
                  start = c(1960, 1), 
                  end = c(2013, 4), 
                  frequency = 4)

# 3-months Treasury bills interest rate
TB3MS <- xts(USMacroSWQ$TB3MS, USMacroSWQ$Date)["1960::2012"]

# 10-years Treasury bonds interest rate
TB10YS <- xts(USMacroSWQ$GS10, USMacroSWQ$Date)["1960::2012"]

# term spread
TSpread <- TB10YS - TB3MS

TSpread_ts <- ts(TSpread, 
                start = c(1960, 1), 
                end = c(2012, 4), 
                frequency = 4)

# join both ts objects
ADLdata <- ts.union(GDPGrowth_ts, TSpread_ts)

```

```{r}
EndOfSample <- seq(2002.75, 2012.5, 0.25)

# initialize matrix forecasts
forecasts <- matrix(nrow = 1, 
                    ncol = length(EndOfSample))

# initialize vector SER
SER  <- numeric(length(EndOfSample))

# estimation loop over end of sample dates
for(i in 1:length(EndOfSample)) {

  # estimate ADL(2,2) model
  m <- dynlm(GDPGrowth_ts ~ L(GDPGrowth_ts) + L(GDPGrowth_ts, 2) 
                          + L(TSpread_ts) + L(TSpread_ts, 2), 
                start = c(1981, 1), 
                end = EndOfSample[i])
  
  SER[i] <- summary(m)$sigma
  
  # sample data for one-period ahead forecast
  s <- window(ADLdata, EndOfSample[i] - 0.25, EndOfSample[i])

 
  # compute forecast
  forecasts[i] <- coef(m) %*% c(1, s[1, 1], s[2, 1], s[1, 2], s[2, 2]) 
}
# compute psuedo-out-of-sample forecast errors
POOSFCE <- c(window(GDPGrowth_ts, c(2003, 1), c(2012, 4))) - forecasts

# series of pseudo-out-of-sample forecasts
PSOSSFc <- ts(c(forecasts), 
              start = 2003, 
              end = 2012.75, 
              frequency = 4)
 predict(m, newdata = s) 
# plot the GDP growth time series
plot(window(GDPGrowth_ts, c(2003, 1), c(2012, 4)),
     col = "steelblue",
     lwd = 2,
     ylab = "Percent",
     main = "Pseudo-Out-Of-Sample Forecasts of GDP Growth") +

# add the series of pseudo-out-of-sample forecasts
lines(PSOSSFc, 
      lwd = 2, 
      lty = 2) +

# shade area between curves (the pseudo forecast error)
polygon(c(time(PSOSSFc), rev(time(PSOSSFc))), 
        c(window(GDPGrowth_ts, c(2003, 1), c(2012, 4)), rev(PSOSSFc)),
        col = alpha("blue", alpha = 0.3),
        border = NA) 

# add a legend
legend("bottomleft", 
       lty = c(1, 2, 1),
       lwd = c(2, 2, 10),
       col = c("steelblue", "black", alpha("blue", alpha = 0.3)), 
       legend = c("Actual GDP growth rate",
         "Forecasted GDP growth rate",
         "Pseudo forecast Error"))

SER[1]
sd(POOSFCE)
predict(unemp_total_modelvar_bic, newdata = s)
```

```{r}
EndOfSample <- seq(2020, 2023, 1/12)

# initialize matrix forecasts
forecasts <- matrix(nrow = 1, 
                    ncol = length(EndOfSample))

# initialize vector SER
SER  <- numeric(length(EndOfSample))

# estimation loop over end of sample dates
for(i in 1:length(EndOfSample)) {

  # estimate Uenemployment Model
  
  unemp_total_modelvar_bic <-  dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12) + L(unemp, 0:1) + season(diff_total_log), start = c(1976,1), end = EndOfSample[i], data = total_unemp_analysis)
  
  
  SER[i] <- summary(unemp_total_modelvar_bic)$sigma

  # sample data for one-period ahead forecast
  s <- window(total_unemp_analysis, EndOfSample[i] - 13/12, EndOfSample[i])

  # compute forecast
  forecasts[i] <- coef(unemp_total_modelvar_bic) %*% c(1, s[1, 1], s[2, 1], s[3,1], s[4,1], s[5,1], s[6,1], s[7,1], s[8,1], s[9,1], s[10,1], s[11,1], s[12, 1], s[12, 2], s[11,2])
}
sd# compute psuedo-out-of-sample forecast errors
POOSFCE <- c(window(diff_total_log, c(2020, 1), c(2023, 1))) - forecasts

# series of pseudo-out-of-sample forecasts
PSOSSFc <- ts(c(forecasts), 
              start = 2020, 
              end = 2023, 
              frequency = 12)

# plot the GDP growth time series
plot(window(diff_total_log, c(2020, 1), c(2023, 1)),
     col = "steelblue",
     lwd = 2,
     ylab = "Percent",
     main = "Pseudo-Out-Of-Sample Forecasts of Difference in Auto Production") +

# add the series of pseudo-out-of-sample forecasts
lines(PSOSSFc, 
      lwd = 2, 
      lty = 2)  +

# shade area between curves (the pseudo forecast error)
polygon(c(time(PSOSSFc), rev(time(PSOSSFc))), 
        c(window(diff_total_log, c(2020, 1), c(2023, 1)), rev(PSOSSFc)),
        col = alpha("blue", alpha = 0.3),
        border = NA) +

# add a legend
legend("bottomleft", 
       lty = c(1, 2, 1),
       lwd = c(2, 2, 10),
       col = c("steelblue", "black", alpha("blue", alpha = 0.3)), 
       legend = c("Actual GDP growth rate",
         "Forecasted GDP growth rate",
         "Pseudo forecast Error"))

SER[1]
sd(POOSFCE)
```

### Gas Forecast

```{r}
EndOfSample_gas <- seq(2020, 2023, 1/12)

# initialize matrix forecasts
forecasts_gas <- matrix(nrow = 1, 
                    ncol = length(EndOfSample_gas))

# initialize vector SER
SER_gas  <- numeric(length(EndOfSample_gas))

# estimation loop over end of sample dates
for(i in 1:length(EndOfSample_gas)) {

# estimate Gas Model
  gas_total_model_autobic <- dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12) + L(gas_cpi, 0:12) + season(diff_total_log), start = c(1976,1), end = EndOfSample_gas[i], data = total_gas_analysis)
  
  
  SER_gas[i] <- summary(gas_total_model_autobic)$sigma

  # sample data for one-period ahead forecast
  s <- window(total_gas_analysis, EndOfSample_gas[i] - 13/12, EndOfSample_gas[i])

  # compute forecast
  forecasts_gas[i] <- coef( gas_total_model_autobic) %*% c(1, s[1, 1], s[2, 1], s[3,1], s[4,1], s[5,1], s[6,1], s[7,1], s[8,1], s[9,1], s[10,1], s[11,1], s[12, 1], s[12, 2], s[11,2])
}
sd# compute psuedo-out-of-sample forecast errors
POOSFCE_gas <- c(window(diff_total_log, c(2020, 1), c(2023, 1))) - forecasts_gas

# series of pseudo-out-of-sample forecasts
PSOSSFc_gas <- ts(c(forecasts_gas), 
              start = 2020, 
              end = 2023, 
              frequency = 12)

# plot the GDP growth time series
plot(window(diff_total_log, c(2020, 1), c(2023, 1)),
     col = "steelblue",
     lwd = 2,
     ylab = "Percent",
     main = "Pseudo-Out-Of-Sample Forecasts of GDP Growth") +

# add the series of pseudo-out-of-sample forecasts
lines(PSOSSFc_gas, 
      lwd = 2, 
      lty = 2)  +

# shade area between curves (the pseudo forecast error)
polygon(c(time(PSOSSFc_gas), rev(time(PSOSSFc_gas))), 
        c(window(diff_total_log, c(2020, 1), c(2023, 1)), rev(PSOSSFc_gas)),
        col = alpha("blue", alpha = 0.3),
        border = NA) 

# add a legend
legend("bottomleft", 
       lty = c(1, 2, 1),
       lwd = c(2, 2, 10),
       col = c("steelblue", "black", alpha("blue", alpha = 0.3)), 
       legend = c("Actual GDP growth rate",
         "Forecasted GDP growth rate",
         "Pseudo forecast Error"))

SER[1]
sd(POOSFCE)
```

### Domestic Auto Production Forecast

```{r}
EndOfSample_prod <- seq(2020, 2023, 1/12)

# initialize matrix forecasts
forecasts_prod <- matrix(nrow = 1, 
                    ncol = length(EndOfSample_prod))

# initialize vector SER
SER_prod  <- numeric(length(EndOfSample_prod))

# estimation loop over end of sample dates
for(i in 1:length(EndOfSample_prod)) {

# estimate Gas Model
  prod_total_model_auto <- dynlm::dynlm(diff_total_log ~ L(diff_total_log, 1:12) + L(auto_prod, 0:10) + season(diff_total_log), start = c(1993,1), end = EndOfSample_prod[i], data = total_prod_analysis)
  
  SER_prod[i] <- summary(prod_total_model_auto)$sigma

  # sample data for one-period ahead forecast
  s_prod <- window(total_prod_analysis, EndOfSample_prod[i] - 13/12, EndOfSample_prod[i])

  # compute forecast
  forecasts_prod[i] <- coef(prod_total_model_auto) %*% c(1, s[1, 1], s[2, 1], s[3,1], s[4,1], s[5,1], s[6,1], s[7,1], s[8,1], s[9,1], s[10,1], s[11,1], s[12, 1], s[12, 2], s[11,2])
}
sd# compute psuedo-out-of-sample forecast errors
POOSFCE_prod <- c(window(diff_total_log, c(2020, 1), c(2023, 1))) - forecasts_prod

# series of pseudo-out-of-sample forecasts
PSOSSFc_prod <- ts(c(forecasts_prod), 
              start = 2020, 
              end = 2023, 
              frequency = 12)

# plot the GDP growth time series
plot(window(diff_total_log, c(2020, 1), c(2023, 1)),
     col = "steelblue",
     lwd = 2,
     ylab = "Percent",
     main = "Pseudo-Out-Of-Sample Forecasts of GDP Growth") +

# add the series of pseudo-out-of-sample forecasts
lines(PSOSSFc_prod, 
      lwd = 2, 
      lty = 2)  +

# shade area between curves (the pseudo forecast error)
polygon(c(time(PSOSSFc_prod), rev(time(PSOSSFc_prod))), 
        c(window(diff_total_log, c(2020, 1), c(2023, 1)), rev(PSOSSFc_prod)),
        col = alpha("blue", alpha = 0.3),
        border = NA) 

# add a legend
legend("bottomleft", 
       lty = c(1, 2, 1),
       lwd = c(2, 2, 10),
       col = c("steelblue", "black", alpha("blue", alpha = 0.3)), 
       legend = c("Actual GDP growth rate",
         "Forecasted GDP growth rate",
         "Pseudo forecast Error"))
```

## Conclusion

## References
